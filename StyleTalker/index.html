<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="FlashAvatar: High-fidelity Head Avatar with Efficient Gaussian Embedding">
  <meta name="keywords" content="3D-GS, head avatar reconstruction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FlashAvatar</title>

  <!-- Bootstrap -->
  <link href="static/css/bootstrap-4.4.1.css" rel="stylesheet">
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h2 class="title is-2 publication-title" style="margin-top: 0; margin-bottom: 2">FlashAvatar: High-fidelity Head Avatar with Efficient Gaussian Embedding</h2>
            <!-- <h2 class="title is-4 publication-title" style="margin-top: 0; margin-bottom: 0">SIGGRAPH Asia 2022 (Journal Track)</h2> -->
          <h2 class="title is-4 publication-title" style="color:#6e6e6e;margin-top: 2; margin-bottom: 2">CVPR 2024</h2>
          <!-- <h2 class="title is-2 publication-title" style="margin-top: 0"></h2> -->

          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://xiangjun-xj.github.io/">Jun Xiang</a></a></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><a href="https://xuanghahahaha.github.io/">Xuan Gao</a></a></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"> <a href="https://yudongguo.github.io/">Yudong Guo</a>
            </span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>
            </span>
          </div>

          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Science and Technology of China</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><sup>2</sup>Image Derivative Inc</span>&nbsp;&nbsp;&nbsp;&nbsp;
          </div> -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">University of Science and Technology of China</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <!-- <span class="author-block"><sup>2</sup>Image Derivative Inc</span>&nbsp;&nbsp;&nbsp;&nbsp; -->
          </div>

          <!-- <div class="is-size-6 publication-authors">
            <span class="author-block">(This work was done when Xuan Gao, Chenglai Zhong and Jun Xiang were intern at Image Derivative Inc.)</span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links" style="margin-top: 0; margin-bottom: 2">
              <!-- PDF Link. -->
              <!--
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2312.02214"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!--
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/USTC3DV/FlashAvatar-code"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!--
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>
              -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!--
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./resources/teaser.png"
                type="video/mp4">
      </video>
      -->
      <img src="https://raw.githubusercontent.com/xiangjun-xj/project_page_assets/master/FlashAvatar/teaser.png" class="center">
      <h2 class="subtitle has-text-centered" style="margin-top: 15px">
        Given a monocular video sequence, our proposed FlashAvatar can reconstruct a high-fidelity digital avatar in minutes which can be animated and rendered over 300FPS at the resolution of 512&times512 with an Nvidia RTX 3090.
      </h2>
    </div>
  </div>
</section>

<!--
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Reconstructions</h2>

        <div class="embed-responsive embed-responsive-16by9">

          <iframe style="clip-path: inset(1px 1px)" src="https://sketchfab.com/playlists/embed?collection=abee3cc1a7a7436c804f2bd3aadc2acd" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture; fullscreen" mozallowfullscreen="true" webkitallowfullscreen="true" width="100%" height="100%" frameborder="0"></iframe>
        </div>
        

      </div>
    </div>

  </div>
</section>

-->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="margin-top: -30px">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We propose FlashAvatar, a novel and lightweight 3D animatable avatar representation that could reconstruct a digital avatar from a short monocular video sequence in minutes and render high-fidelity photo-realistic images at 300FPS on a consumer-grade GPU. To achieve this, we maintain a uniform 3D Gaussian field embedded in the surface of a parametric face model and learn extra spatial offset to model non-surface regions and subtle facial details. While full use of geometric priors can capture high-frequency facial details and preserve exaggerated expressions, proper initialization can help reduce the number of Gaussians, thus enabling super-fast rendering speed. Extensive experimental results demonstrate that FlashAvatar outperforms existing works regarding visual quality and personalized details and is almost an order of magnitude faster in rendering speed.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <!-- Paper video. -->
    <!--
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    -->
    <!--/ Paper video. -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">Pipeline</h2>

        <img src="https://raw.githubusercontent.com/xiangjun-xj/project_page_assets/master/FlashAvatar/pipeline.png" class="center">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            We initially maintain the 3D Gaussian field in 2D UV space and embed them into dynamic FLAME mesh surfaces through mesh rasterization. For every surface-embedded 3D Gaussian, the offset network takes tracked expression code and the corresponding position of the Gaussian center on canonical mesh as input, outputs the spatial offset, including position, rotation, and scaling deformation. The deformed Gaussians are then splatted to render the image with a given pose.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="https://raw.githubusercontent.com/xiangjun-xj/project_page_assets/master/FlashAvatar/pipeline.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Results. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Comparison</h2>

        <div class="content has-text-justified">
          <p>
            We compare our method with three representative works. As we can see, FlashAvatar produces photo-realistic images most consistent with the ground truth. We recover almost all fine facial details, thin structures, and subtle expressions with 3D Gaussians in 10K level. As both mesh dynamics and later Gaussian deformation condition on tracked expression code disentangled from identity space, we could conduct facial reenactment task at super-fast rendering speed with no difficulty. Note that for PointAvatar, the full training requires 80GB A100 GPU, but we train it on 32GB V100 and use fewer points and earlier checkpoints exactly following the author's suggestions. All other experiments were done on 24GB Nvidia RTX 3090.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="https://raw.githubusercontent.com/xiangjun-xj/project_page_assets/master/FlashAvatar/comparison.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>

  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Comparisons. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Training
        </h2>

        <div class="content has-text-justified">
          <p>
            We achieve a remarkable rendering speed over 300FPS. Meanwhile, we demonstrate that our training process is super efficient as well. We are able to recover the coarse appearance of head in several seconds and reconstruct the photo-realistic avatar with fine hair strands and textures within a couple of minutes. We conduct both training and inference on a single Nvidia RTX 3090.            
          </p>
        </div>
        
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="https://raw.githubusercontent.com/xiangjun-xj/project_page_assets/master/FlashAvatar/training.mp4"
                    type="video/mp4">
          </video>
        </div>


      </div>
    </div>

  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Ablation Studies. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Novel View Synthesis</h2>

        <div class="content has-text-justified">
          <p>
            The basic representation of 3D head avatars in our method is pure non-neural 3D Gaussians, so we can freely adjust the global camera pose to generate target results with any desired rendering view.
          </p>
        </div>
        
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="https://raw.githubusercontent.com/xiangjun-xj/project_page_assets/master/FlashAvatar/nvs.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
    </div>

  </div>
</section>

<!-- <section class="hero is-light is-small">
  <div class="hero-body"> -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered" style="margin-top: -30px">More Results</h2>
    <!-- Begin gallery-1. -->
    <div class="container">
      <div id="results-carousel1" class="carousel results-carousel">
        <div class="item g11">
          <video poster="" id="g11" controls muted loop playsinline height="100%">
            <source src="https://raw.githubusercontent.com/xiangjun-xj/project_page_assets/master/FlashAvatar/id3_12.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item g12">
          <video poster="" id="g12" controls muted loop playsinline height="100%">
            <source src="https://raw.githubusercontent.com/xiangjun-xj/project_page_assets/master/FlashAvatar/person0_12.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item g13">
          <video poster="" id="g13" controls muted loop playsinline height="100%">
            <source src="https://raw.githubusercontent.com/xiangjun-xj/project_page_assets/master/FlashAvatar/id5_12.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item g14">
          <video poster="" id="g14" controls muted loop playsinline height="100%">
            <source src="https://raw.githubusercontent.com/xiangjun-xj/project_page_assets/master/FlashAvatar/malte_12.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!-- <div class="item g15">
          <video poster="" id="g15" controls muted loop playsinline height="100%">
            <source src="https://raw.githubusercontent.com/HaiyaoX/project_page_assets/main/video_demo/zcl_roman_x264.mp4"
                    type="video/mp4">
        </video>
        </div> -->
      </div>
    </div>
  <!-- <h2 class="subtitle has-text-centered" style="margin-top: 15px">
    We present CosAvatar, a text-driven portrait editing framework based on monocular dynamic NeRF. It allows for both global style editing (top row) and local attribute editing (bottom row) while ensuring strong consistency. It also enables expressive animation of the edited portrait.
  </h2> -->
  <div class="content has-text-justified">
    <p>
      In this paper, we have proposed FlashAvatar, which tightly combines a non-neural Gaussian-based radiance field with an explicit parametric face model and takes full advantage of their respective strengths. As a result, it can reconstruct a digital avatar from a monocular video in minutes and animate it at 300FPS while achieving photo-realistic rendering with full personalized details. Its efficiency, robustness, and representation ability have also been verified by extensive experimental results.
    </p>
  </div>

  </div>
</section>
<!-- End gallery. -->




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <div class="content has-text-justified">
      <p>
        If you find our paper useful for your work please cite:
      </p>
    </div>
    <pre><code>
      @inproceedings{xiang2024flashavatar,
        author    = {Jun Xiang and Xuan Gao and Yudong Guo and Juyong Zhang},
        title     = {FlashAvatar: High-fidelity Head Avatar with Efficient Gaussian Embedding},
        booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
        year      = {2024},
      }
    </code></pre>
  </div>
</section>



<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    This work was supported by the National Natural Science Foundation of China (No. 62122071, No. 62272433) and the Youth Innovation Promotion Association CAS (No. 2018495).
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            This webpage template is from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
            We sincerely thank <a href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template.
          </p>
        </div>
      </div>
          <p></p>
        </div>
      </div>
</footer>

</body>
</html>
